{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QdH_FGR2KVDu",
        "-UKCXasxKI3r"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauragj95/landmarks-navigation-and-recognition/blob/main/SRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3dSzFsDKLPH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8e28ca4-efeb-40eb-863e-23eb56dbe8d6"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiqNX9W-ikKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "990816a4-2ba9-467e-ada5-9345b8e72bba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/src/Gan/SRGAN_Modules')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LylM54pYZv2q"
      },
      "source": [
        "#Copio el contenido de esta carpeta en la VM para que vaya mas rapido (Tarda mucho en copiar)\n",
        "!cp -r \"/content/drive/My Drive/src/Gan/People_faces_256x256/\" ./People_faces_256x256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZVx-_yah3Gs"
      },
      "source": [
        "from Network import Generator, Discriminator\n",
        "import Utils, Utils_model\n",
        "from Utils_model import VGG_LOSS\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import load_model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import argparse\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf0W_epE9KVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1fa057e1-fb41-4246-b243-7349d8d05496"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPTVJeVssNSf"
      },
      "source": [
        "np.random.seed(10)\n",
        "# LR images shape target\n",
        "target = 32\n",
        "# Remember to change image shape if you are having different size of images\n",
        "image_shape = (256,256,3)\n",
        "# Better to use downscale factor as 4\n",
        "downscale_factor = int(image_shape[0]/target)\n",
        "\n",
        "LAMBDA = 100\n",
        "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVYqsf4E_8oi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1269162-e07a-4af2-8bd7-d002df68532b"
      },
      "source": [
        "downscale_factor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy0rv5D8sOMA"
      },
      "source": [
        "# Combined network\n",
        "def get_gan_network(discriminator, shape, generator, optimizer, loss):\n",
        "    discriminator.trainable = False\n",
        "    gan_input = Input(shape=shape)\n",
        "    x = generator(gan_input)\n",
        "    \n",
        "\n",
        "    gan_output = discriminator(x)\n",
        "\n",
        "    gan = Model(inputs=gan_input, outputs=[x, gan_output])\n",
        "    gan.compile(loss=[loss, \"binary_crossentropy\"],\n",
        "                loss_weights=[1., 1e-3],\n",
        "                optimizer=optimizer)\n",
        "    ###Añadido\n",
        "    gan.summary()\n",
        "    discriminator.trainable = True\n",
        "    ####------\n",
        "    return gan"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UatyB_5dQQu4"
      },
      "source": [
        "def save(gan, generator, discriminator, optimizer, loss, model_path, epoch):\n",
        "\n",
        "    discriminator.trainable = False\n",
        "    gan.save(model_path + '%d_gan_model' % epoch, save_format = 'tf')\n",
        "    gan.compile(loss=[loss, \"binary_crossentropy\"], optimizer=optimizer)\n",
        "    discriminator.trainable = True\n",
        "\n",
        "    discriminator.save(model_path + '%d_dis_model' % epoch, save_format = 'tf')\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "\n",
        "    generator.save(model_path + '%d_gen_model' % epoch, save_format = 'tf')\n",
        "    generator.compile(loss=loss, optimizer=optimizer)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5yBjw168SHK"
      },
      "source": [
        "def custom_vgg_loss(y_true, y_pred):\n",
        "\n",
        "    vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=image_shape)\n",
        "    vgg19.trainable = False\n",
        "    # Make trainable as False\n",
        "    for l in vgg19.layers:\n",
        "        l.trainable = False\n",
        "    #tf.config.experimental_run_functions_eagerly(True)\n",
        "    model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)\n",
        "    model.trainable = False\n",
        "\n",
        "    return K.mean(K.square(model(y_true) - model(y_pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT3EXjIrQQlZ"
      },
      "source": [
        "def load(model_path, epoch):\n",
        "\n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "\n",
        "    generator = load_model(model_path + '%d_gen_model' % epoch, custom_objects={ 'vgg_loss': loss.vgg_loss })\n",
        "    discriminator = load_model(model_path + '%d_dis_model' % epoch)\n",
        "    gan = load_model(model_path + '%d_gan_model' % epoch, custom_objects={ 'vgg_loss': loss.vgg_loss })\n",
        "\n",
        "    generator.summary()\n",
        "    discriminator.summary()\n",
        "    gan.summary()\n",
        "    return gan, generator, discriminator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O_2S8lfyrtq"
      },
      "source": [
        "#gan, generator, discriminator = load(\"/content/drive/My Drive/src/Gan/SRGAN_model/\", 25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdNGMiTyYgob"
      },
      "source": [
        "**Discriminator loss**\n",
        "  * The discriminator loss function takes 2 inputs; **real images, generated images**\n",
        "  * real_loss is a sigmoid cross entropy loss of the **real images** and an **array of ones(since these are the real images)**\n",
        "  * generated_loss is a sigmoid cross entropy loss of the **generated images** and an **array of zeros(since these are the fake images)**\n",
        "  * Then the total_loss is the sum of real_loss and the generated_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ8rUbEPXwIQ"
      },
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n",
        "\n",
        "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  total_disc_loss = real_loss + generated_loss\n",
        "  return total_disc_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjn9UdahYeBR"
      },
      "source": [
        " **Generator loss**\n",
        "  * It is a sigmoid cross entropy loss of the generated images and an **array of ones**.\n",
        "  * The [paper](https://arxiv.org/abs/1611.07004) also includes L1 loss which is MAE (mean absolute error) between the generated image and the target image.\n",
        "  * This allows the generated image to become structurally similar to the target image.\n",
        "  * The formula to calculate the total generator loss = gan_loss + LAMBDA * l1_loss, where LAMBDA = 100. This value was decided by the authors of the [paper](https://arxiv.org/abs/1611.07004).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpY-yQVfXv-y"
      },
      "source": [
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n",
        "\n",
        "  # mean absolute error\n",
        "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "\n",
        "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "  return total_gen_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyowrxdwOYL9"
      },
      "source": [
        "#No usada, no funciona dado que keras no guarda el estado de las capas del discriminador\n",
        "def save_optimizer_states(model, name, model_save_dir):\n",
        "\n",
        "  symbolic_weights = getattr(model.optimizer, 'weights')\n",
        "  weight_values = K.batch_get_value(symbolic_weights)\n",
        "  with open(model_save_dir + name, 'wb') as f:\n",
        "      pickle.dump(weight_values, f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSy7qdigYvC_"
      },
      "source": [
        "**Training**\n",
        "* No need to iterate over the dataset. We do all the calculations at the same time.\n",
        "* The generator gets the input image and we get a generated output.\n",
        "* The discriminator receives the input_image and the generated image as the first input. The second input is the input_image and the target_image.\n",
        "* Next, we calculate the generator and the discriminator loss.\n",
        "* Then, we calculate the gradients of loss with respect to both the generator and the discriminator variables(inputs) and apply those to the optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCIobFfJQzIf"
      },
      "source": [
        "@tf.function\n",
        "def train_step(shape_lr, input_image, target, g_loss_metric, d_loss_metric, generator, discriminator, generator_optimizer, discriminator_optimizer):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    print(input_image)\n",
        "    gen_output = generator(input_image, training=True)\n",
        "\n",
        "    disc_real_output = discriminator(target, training=True)\n",
        "    disc_generated_output = discriminator(target, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "\n",
        "  # Update the metrics\n",
        "  g_loss_metric.update_state(gen_loss)\n",
        "  d_loss_metric.update_state(disc_loss)\n",
        "  # accuracy_metric.update_state(tf.ones_like(gen_output), gen_output)\n",
        "  generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdH_FGR2KVDu"
      },
      "source": [
        "# **`Entrenamiento (funcion antigua)`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGLC9Vp4Sow8"
      },
      "source": [
        "def old_train(x_train_lr, x_train_hr, x_test_lr, x_test_hr, epochs, batch_size, output_dir, model_save_dir, weights_save_dir):\n",
        "  loss = VGG_LOSS(image_shape)  \n",
        "    \n",
        "  batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "  #### SI LAS IMAGENES NO SON CUADRADAS ESTO DEBERIA CAMBIAR\n",
        "  shape_lr = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "  shape_hr = x_train_hr[0].shape\n",
        "  ####\n",
        "\n",
        "  gen = Generator(shape_lr, shape_hr).generator()\n",
        "  dis = Discriminator(image_shape).discriminator()\n",
        "\n",
        "  optimizer = Utils_model.get_optimizer()\n",
        "  gen.compile(loss=loss.vgg_loss, optimizer=optimizer)\n",
        "  dis.compile(loss=\"binary_crossentropy\", optimizer=optimizer)\n",
        "\n",
        "  gan = get_gan_network(dis, shape_lr, gen, optimizer, loss.vgg_loss)\n",
        "  \n",
        "  loss_file = open(model_save_dir + '/losses.txt' , 'w+')\n",
        "  loss_file.close()\n",
        "\n",
        "  for e in range(1, epochs+1):\n",
        "      print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "      for _ in tqdm(range(batch_count)):\n",
        "          \n",
        "          rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "          \n",
        "          image_batch_hr = x_train_hr[rand_nums]\n",
        "          image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "          generated_images_sr = gen.predict(image_batch_lr)\n",
        "\n",
        "          real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "          fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "          \n",
        "          dis.trainable = True\n",
        "          \n",
        "          d_loss_real = dis.train_on_batch(image_batch_hr, real_data_Y)\n",
        "          d_loss_fake = dis.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "          discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "          \n",
        "          rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "          image_batch_hr = x_train_hr[rand_nums]\n",
        "          image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "          gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "          dis.trainable = False\n",
        "          gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr, gan_Y])\n",
        "          \n",
        "          \n",
        "      print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "      print(\"gan_loss :\", gan_loss)\n",
        "      gan_loss = str(gan_loss)\n",
        "      \n",
        "      loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "      loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "      loss_file.close()\n",
        "\n",
        "      if e == 1 or e % 5 == 0:\n",
        "          Utils.plot_generated_images(output_dir, e, gen, x_test_hr, x_test_lr)\n",
        "\n",
        "          save(gan, gen, dis, optimizer, loss.vgg_loss, model_save_dir, e)\n",
        "\n",
        "      if e % 500 == 0 or e == epochs+1:\n",
        "          Utils.plot_generated_images(output_dir, e, gen, x_test_hr, x_test_lr)\n",
        "\n",
        "          save(gan, gen, dis, optimizer, loss.vgg_loss, model_save_dir, e)\n",
        "        \n",
        "          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vELwasgiWzX9"
      },
      "source": [
        "#  ENTRENAMIENTO "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKqC_CIwsUvq"
      },
      "source": [
        "def train(one_sample, x_train_lr, x_train_hr, x_test_lr, x_test_hr, epochs, batch_size, output_dir, model_save_dir, weights_save_dir):\n",
        "\n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    image_batch_hr = tf.split(x_train_hr, num_or_size_splits = batch_count)    \n",
        "    image_batch_lr = tf.split(x_test_lr, num_or_size_splits = batch_count)\n",
        "\n",
        "\n",
        "    shape_lr = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "    shape_hr = x_train_hr[0].shape\n",
        "    print(type(one_sample))\n",
        "    # Create the metrics\n",
        "    g_loss_log = []\n",
        "    d_loss_log = []\n",
        "    g_loss_metric = tf.keras.metrics.Mean(name='g_train_loss')\n",
        "    d_loss_metric = tf.keras.metrics.Mean(name='d_train_loss')\n",
        "    accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    generator = Generator()\n",
        "    generator_out = generator(one_sample, training = False)\n",
        "\n",
        "    discriminator = Discriminator()\n",
        "    discriminator_out = discriminator(shape_hr, training = False)\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                              discriminator_optimizer=discriminator_optimizer,\n",
        "                              generator=generator, discriminator=discriminator)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "      start = time.time()\n",
        "      # Reset the metrics\n",
        "      g_loss_metric.reset_states()\n",
        "      d_loss_metric.reset_states()\n",
        "      counter = 0\n",
        "\n",
        "      for i in tqdm(range(batch_count)):\n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr_slice = image_batch_hr[i]\n",
        "            image_batch_lr_slice = image_batch_lr[i]\n",
        "            \n",
        "            for image_hr, image_lr in zip(image_batch_hr_slice, image_batch_lr_slice):\n",
        "              train_step(shape_lr, image_lr, image_hr, g_loss_metric, d_loss_metric, \n",
        "                        generator, discriminator, generator_optimizer, discriminator_optimizer)\n",
        "\n",
        "      # Get the metric results\n",
        "      g_mean_loss = g_loss_metric.result()\n",
        "      d_mean_loss = d_loss_metric.result()\n",
        "      g_loss_log.append([g_mean_loss])\n",
        "      d_loss_log.append([d_mean_loss])\n",
        "      # mean_accuracy = accuracy_metric.result()\n",
        "\n",
        "      print('Epoch: ', epoch)\n",
        "      print('  loss (g) (d) (g+d):     {:.3f}, {:.3f}, {:.3f}'.format(g_mean_loss, d_mean_loss, g_mean_loss + d_mean_loss))\n",
        "\n",
        "      if (epoch) % 5 == 0 or epoch == 1:\n",
        "          Utils.plot_generated_images(output_dir, e, gen, x_test_hr, x_test_lr)\n",
        "          plot_losses(g_loss_log, d_loss_log, epoch=epoch, dataset='dataset')\n",
        "\n",
        "          checkpoint.save(file_prefix = os.path.join(output_dir, 'training_checkpoints', \"ckpt\"))\n",
        "\n",
        "      print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n",
        "                                                          time.time()-start))         "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UKCXasxKI3r"
      },
      "source": [
        "# **`Continuar entrenamiento`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfPWKOZDZv_t"
      },
      "source": [
        "\n",
        "##NO TENER EN CUENTA. SE TIENE QUE MODIFICAR\n",
        "def resume_training(current_epoch, x_train_lr, x_train_hr, x_test_lr, x_test_hr, epochs, batch_size, output_dir, model_save_dir):\n",
        "\n",
        "    batch_count = int(x_train_hr.shape[0] / batch_size)\n",
        "    #### SI LAS IMAGENES NO SON CUADRADAS ESTO DEBERIA CAMBIAR\n",
        "    shape_lr = (image_shape[0]//downscale_factor, image_shape[1]//downscale_factor, image_shape[2])\n",
        "    shape_hr = x_train_hr[0].shape\n",
        "\n",
        "    #gan, generator, discriminator = load(model_save_dir, current_epoch)\n",
        "      \n",
        "\n",
        "\n",
        "    loss = VGG_LOSS(image_shape)  \n",
        "\n",
        "\n",
        "    generator = load_model(model_save_dir + '%d_gen_model' % current_epoch, custom_objects={ 'vgg_loss': loss.vgg_loss })\n",
        "\n",
        "    discriminator = load_model(model_save_dir + '%d_dis_model' % current_epoch)\n",
        "\n",
        "    gan = load_model(model_save_dir + '%d_gan_model' % current_epoch, custom_objects={ 'vgg_loss': loss.vgg_loss })\n",
        "\n",
        "\n",
        "\n",
        "    #generator = load_model(model_path + '%d_gen_model' % epoch, custom_objects={ 'vgg_loss': loss.vgg_loss })\n",
        "    #discriminator = load_model(model_path + '%d_dis_model' % epoch)\n",
        "    #gan = load_model(model_path + '%d_gan_model' % epoch, custom_objects={ 'vgg_loss': loss.vgg_loss })\n",
        "\n",
        "    generator.summary()\n",
        "    discriminator.summary()\n",
        "    gan.summary()\n",
        "\n",
        "    loss_file = open(model_save_dir + 'losses.txt' , 'w+')\n",
        "    loss_file.close()\n",
        "\n",
        "    for e in range(current_epoch+1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batch_count)):\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            \n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            generated_images_sr = generator.predict(image_batch_lr)\n",
        "\n",
        "            real_data_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            fake_data_Y = np.random.random_sample(batch_size)*0.2\n",
        "            \n",
        "            discriminator.trainable = True\n",
        "            \n",
        "            d_loss_real = discriminator.train_on_batch(image_batch_hr, real_data_Y)\n",
        "            d_loss_fake = discriminator.train_on_batch(generated_images_sr, fake_data_Y)\n",
        "            discriminator_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
        "            \n",
        "            rand_nums = np.random.randint(0, x_train_hr.shape[0], size=batch_size)\n",
        "            image_batch_hr = x_train_hr[rand_nums]\n",
        "            image_batch_lr = x_train_lr[rand_nums]\n",
        "\n",
        "            gan_Y = np.ones(batch_size) - np.random.random_sample(batch_size)*0.2\n",
        "            discriminator.trainable = False\n",
        "            gan_loss = gan.train_on_batch(image_batch_lr, [image_batch_hr, gan_Y])\n",
        "            \n",
        "            \n",
        "        print(\"discriminator_loss : %f\" % discriminator_loss)\n",
        "        print(\"gan_loss :\", gan_loss)\n",
        "        gan_loss = str(gan_loss)\n",
        "        \n",
        "        loss_file = open(model_save_dir + 'losses.txt' , 'a')\n",
        "        loss_file.write('epoch%d : gan_loss = %s ; discriminator_loss = %f\\n' %(e, gan_loss, discriminator_loss) )\n",
        "        loss_file.close()\n",
        "\n",
        "        if e == 1 or e % 5 == 0:\n",
        "            Utils.plot_generated_images(output_dir, e, generator, x_test_hr, x_test_lr)\n",
        "\n",
        "            save(gan, generator, discriminator, model_save_dir, e)\n",
        "\n",
        "\n",
        "        if e % 500 == 0 or e == epochs+1:\n",
        "            Utils.plot_generated_images(output_dir, e, generator, x_test_hr, x_test_lr)\n",
        "\n",
        "            save(gan, generator, discriminator, model_save_dir, e)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkDQBVYWk0g4"
      },
      "source": [
        "# **`Cargar datos almacenados en la VM`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05WKMNALXWyF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7b89f022-ecc6-40c1-aab1-86c9b9afc114"
      },
      "source": [
        "x_train_lr, x_train_hr, x_test_lr, x_test_hr = Utils.old_load_training_data('./People_faces_256x256/', '.jpg', 0.8, downscale_factor) \n",
        "print('#'*10 + ' LOADED ' + '#'*10) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  2%|#                                                                        |"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Getting images paths...\n",
            "Done\n",
            "Reading images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|#########################################################################|\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Images loaded!\n",
            "Total images: 5000\n",
            "Number of train images:4000\n",
            "Downscale factor: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz2ka-kpk-Tw"
      },
      "source": [
        "# **`Cargar datos almacenados en la nube`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Aa08SwoLe8z"
      },
      "source": [
        "    #x_train_lr, x_train_hr, x_test_lr, x_test_hr = Utils.load_training_data('/content/drive/My Drive/src/Gan/People_faces_256x256/', '.jpg', 0.8, downscale_factor) \n",
        "    #print('#'*10 + ' LOADED ' + '#'*10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_ZIZGyalFm9"
      },
      "source": [
        "# **`Entrenar`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtoSKRpZsY2h"
      },
      "source": [
        "train(one_sample, x_train_lr, x_train_hr, x_test_lr, x_test_hr, 100, 20, \"/content/drive/My Drive/src/Gan/SRGAN_output/\", \"/content/drive/My Drive/src/Gan/SRGAN_model/\", \"/content/drive/My Drive/src/Gan/SRGAN_weights/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6UynXiUlPtf"
      },
      "source": [
        "# **`Continuar entrenamiento`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK_G5cAllMnN"
      },
      "source": [
        "#resume_training(20, x_train_lr, x_train_hr, x_test_lr, x_test_hr, 100, 10, \"/content/drive/My Drive/src/Gan/SRGAN_output/\", \"/content/drive/My Drive/src/Gan/SRGAN_model/\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}